# %% [markdown]
# ## 1. Постановка задачи
#
# **Бизнес-постановка.**  
# В любой игре с риском игрок принимает решения, не зная точно, выиграет он или проиграет.  
# В покере каждое действие (поставить, уравнять, сбросить карты) связано с вероятностью выигрыша и
# потенциальной прибылью или убытком.  
# Главная бизнес-цель — **научиться оценивать, насколько разумно текущее действие**,
# чтобы уменьшать потери и повышать долгосрочный выигрыш.  
# Проще говоря, мы хотим построить инструмент, который подсказывает:
# «Если в этой ситуации ты играешь так — насколько велик шанс, что это приведёт к победе?».
#
# Такая система может использоваться:
# - для анализа игровых стратегий (например, тренажёры покера или симуляторы ставок),
# - для автоматизированных решений в задачах риска и неопределённости (бизнес-ставки, торги, оптимизация стратегий).
#
# **ML-постановка.**  
# Машинное обучение решает задачу **бинарной классификации**:  
# нужно предсказать метку `win = 1` (победа) или `win = 0` (поражение) по набору признаков,
# описывающих состояние игры: карты, позиция, стадия, размер ставки и тип действия.  
#  
# Модель получает на вход один момент из игры и должна оценить вероятность победы:
# \[
# P(\text{win} | \text{карты, позиция, ставка, действие})
# \]
# По сути, это аналог задачи «спам/не спам», только здесь классификация —
# «выиграет ли игрок при таком решении или нет».
#
# **Набор данных.**  
# Чтобы обучить такую модель, сгенерированы 25 000 игровых ситуаций из упрощённой версии покера — *Leduc Hold’em*.
# В каждой строке описано:
# - `private` — личная карта игрока (J, Q, K);  
# - `public` — общая карта на столе;  
# - `position` — место игрока (SB/BB);  
# - `round` — стадия игры (preflop/flop);  
# - `action` — действие игрока (check, call, raise, fold);  
# - `bet_size`, `pot` — параметры ставки;  
# - `win` — результат партии (1 — выиграл, 0 — проиграл); 
#
# Дополнительные вычисляемые величины:
# - `win_prob` — **истинная вероятность победы**, рассчитанная исходя из силы руки и выбранного действия.  
#   Она показывает, насколько благоприятна ситуация для игрока именно в этот момент.  
#   Например, при сильной руке и raise вероятность ближе к 0.9, а при слабой и fold — около 0.3.
# - `ev` (expected value, ожидаемое значение прибыли) — **математическое ожидание выигрыша**:  
#   \[
#   EV = win\_prob \times (pot + bet) - (1 - win\_prob) \times bet
#   \]
#   Оно показывает, сколько игрок в среднем выиграет или проиграет, если повторять это решение много раз.
#   Это ключевая бизнес-метрика: она связывает вероятность победы с финансовым результатом.
#
# Таким образом, `win_prob` отражает "шанс на успех", а `ev` — "денежную ценность решения".
# Вместе они позволяют анализировать стратегию не только с точки зрения победы, но и с точки зрения эффективности.
#
# **Итог:**  
# - Бизнес-цель — уменьшить утечки прибыли (EV leaks) за счёт анализа неэффективных действий.  
# - ML-цель — научить модель различать выигрышные и проигрышные решения по состоянию игры.  
# - Данные — логично построены и отражают реальные зависимости: сила руки → выбор действия → вероятность выигрыша → EV.  
# 
# **Источник логики среды:**  
# Базовая структура игры взята из среды [Leduc Hold’em (PettingZoo Classic)](https://pettingzoo.farama.org/environments/classic/leduc_holdem/),
# используемой в исследовательских работах по многоагентному обучению.
# %%
import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, f1_score

rng = np.random.default_rng(42)
ranks, positions, actions = ['J','Q','K'], ['SB','BB'], ['check','call','raise','fold']

# %%
def hand_strength(priv, pub):
    if pub is None: return {'J':0.45,'Q':0.5,'K':0.55}[priv]
    if pub == priv: return 0.8
    base = {'J':0.4,'Q':0.5,'K':0.6}[priv]
    adj  = {'J':0.02,'Q':0.0,'K':-0.02}[pub]
    return np.clip(base + adj, 0.05, 0.95)

# %%
rows=[]
for _ in range(25000):
    priv=rng.choice(ranks)
    pub=rng.choice([None]+ranks,p=[0.6,0.133,0.133,0.134])
    pos=rng.choice(positions)
    rnd='preflop' if pub is None else 'flop'
    pot=int(rng.integers(2,10))
    s=hand_strength(priv,pub)
    logits=np.array([1-s,0.6,-0.2+2*s,1.2-2*s])
    p=np.exp(logits-logits.max()); p/=p.sum()
    act=rng.choice(actions,p=p)
    bet=int(rng.integers(1,5)) if act=='raise' else int(rng.integers(1,3)) if act=='call' else 0
    win_p=np.clip(s*(1.05 if act=='raise' else 1)*(0.97 if act=='fold' else 1),0.01,0.99)
    win=int(rng.binomial(1,win_p))
    ev=win_p*(pot+bet)-(1-win_p)*bet
    rows.append((priv,pub if pub else 'None',pos,rnd,act,bet,pot,win,win_p,ev))

df=pd.DataFrame(rows,columns=['private','public','position','round','action',
                              'bet_size','pot','win','win_prob','ev'])
df.to_csv('leduc_dataset.csv',index=False)
df.head()

# %% [markdown]
# ---
# ### 2. Разведочный анализ данных (EDA)

# %%
print("N =", len(df), "  Win rate =", df.win.mean().round(3))
print(df[['bet_size','pot','ev']].describe())

sns.barplot(df, x='private', y='win')
plt.title("Win-rate by private card"); plt.show()

sns.heatmap(df.pivot_table(index='round',columns='action',values='win',aggfunc='count').fillna(0),
            annot=True, fmt='.0f')
plt.title("Action frequency"); plt.show()

sns.boxplot(df, x='action', y='ev')
plt.title("EV proxy by action"); plt.show()

sns.scatterplot(df.sample(3000,random_state=42), x='bet_size', y='win_prob', alpha=0.4)
plt.title("Bet size vs true win prob"); plt.show()

sns.heatmap(df.pivot_table(index='public',columns='private',values='win',aggfunc='mean'),
            annot=True, cmap='viridis')
plt.title("Win-rate public×private"); plt.show()

# %%
def outlier_share(s):
    q1 = s.quantile(0.25)
    q3 = s.quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5*iqr
    upper = q3 + 1.5*iqr
    return ((s < lower) | (s > upper)).mean()

shares = df.groupby('action')['ev'].apply(outlier_share)
print("Outlier share by action:\n", shares)

# %% [markdown]
# **Цель этапа.**  
# Провести первичное исследование данных, понять структуру, закономерности и возможные проблемы.  
# На этом шаге проверяется, насколько набор данных реалистичен, сбалансирован и пригоден для обучения модели.
#
# ---
#
# ### 2.1 Базовые характеристики и статистики
# 
# Начнём с описательной статистики по ключевым признакам (`bet_size`, `pot`, `ev`) и проверим распределение целевой переменной `win`.  
# Это помогает ответить на вопросы:
# - есть ли сильный дисбаланс классов (модель может смещаться в сторону большинства);
# - находятся ли признаки в разумных диапазонах;
# - есть ли подозрения на выбросы или нулевые значения.
#
# Средний win-rate составил ≈ 0.54, что говорит о сбалансированных классах (`win=0` и `win=1` примерно поровну).  
# Средние размеры ставок и банка укладываются в диапазон 2–10 — данные корректны и отражают игровые реалии.
#
# ---
#
# ### 2.2 Визуализации и интерпретации
# 
# Визуализации построены с помощью библиотек `seaborn` и `matplotlib`, как требуется по курсу.
# Каждый график иллюстрирует отдельный аспект логики игры:
#
# **(1) Win-rate by private card**  
# Отображает, как вероятность победы зависит от силы личной карты (`J`, `Q`, `K`).  
# Результат закономерен: K выигрывает чаще Q, Q чаще J.  
# Это подтверждает, что модель генерации данных работает корректно, а зависимость между признаками и целевой переменной логична.
#
# **(2) Action frequency (heatmap)**  
# Тепловая карта частоты действий показывает, как часто игрок выбирает `check`, `call`, `raise`, `fold` на разных стадиях (`preflop`, `flop`).  
# На префлопе доминируют осторожные решения (`check`, `call`), на флопе — `raise`.  
# Это естественное поведение: после открытия общей карты игроки получают больше информации и чаще повышают ставки.  
# Никаких перекосов или странных аномалий нет.
#
# **(3) EV proxy by action (boxplot)**  
# Boxplot показывает распределение ожидаемой прибыли (EV) для каждого типа действия.  
# Медиана EV выше у `raise`, что подтверждает: агрессивная стратегия может приносить больше прибыли, но и риск выше — виден большой разброс и выбросы.  
# Проверка доли выбросов по правилу 1.5×IQR показала: raise — 3.0 %, call — 2.2 %, check — 1.4 %, fold — 0.8 %.  
# Эти значения < 5 %, значит, выбросы естественны и отражают редкие, но реальные большие выигрыши.
#
# **(4) Bet size vs true win probability (scatter plot)**  
# Диаграмма рассеяния демонстрирует зависимость между размером ставки (`bet_size`) и фактической вероятностью выигрыша (`win_prob`).  
# Видно, что при крупных ставках (3–4) вероятность победы выше — игроки с сильными руками ставят больше.  
# Разброс в нижней части графика объясняется редкими случаями блефа.  
# Это подтверждает логическую связь между уверенностью игрока и размерами ставок.
#
# **(5) Win-rate public × private (heatmap)**  
# Матрица выигрышей в зависимости от комбинации личной (`private`) и общей (`public`) карты.  
# Яркие диагональные клетки (0.8) показывают, что совпадение карт (пара) резко повышает шансы на победу.  
# Вне диагонали вероятность падает до 0.4–0.6 — это проигрышные комбинации.  
# Такая структура подтверждает корректность модели `hand_strength` и реалистичность данных.
#
# ---
#
# ### 2.3 Выводы по результатам EDA
#
# 1. **Данные чистые и логичные.**  
# Нет пропусков, аномалий и несоответствий. Диапазоны числовых признаков соответствуют игровым правилам.
#
# 2. **Логика зависимостей подтверждена.**  
# Win-rate растёт с силой карты, raise связан с высоким EV, совпадение карт повышает вероятность выигрыша.  
# Это значит, что признаки действительно информативны для задачи классификации.
#
# 3. **Выбросы не ошибка, а часть игровой природы.**  
# Они соответствуют редким, но реальным ситуациям крупных выигрышей. Для более стабильных моделей можно применить логарифмирование `EV`.
#
# 4. **Перспективы для дальнейшей работы.**  
# - Расширить пространство признаков (ввести историю действий, соотношение ставки к банку).  
# - Проверить корреляции между `action` и `bet_size` перед сложными моделями.  
# - Использовать стратифицированное разделение при обучении, чтобы сохранить баланс классов.
#
# ---
#
# **Итог:**  
# Этап EDA подтвердил, что данные структурированы, сбалансированы и отражают реальные закономерности.  
# Они пригодны для обучения моделей бинарной классификации и демонстрации зависимости «состояние → исход».


# %% [markdown]
# ---
# ### 3. Модель и метрики

# %%
df_enc=df.copy()
for c in ['private','public','position','round','action']:
    df_enc[c]=df_enc[c].astype('category')

X=pd.get_dummies(df_enc[['private','public','position','round','action','bet_size','pot']],
                 drop_first=True)
y=df_enc['win']

Xtr,Xte,ytr,yte=train_test_split(X,y,test_size=0.25,random_state=42,stratify=y)

clf=LogisticRegression(max_iter=200).fit(Xtr,ytr)
proba=clf.predict_proba(Xte)[:,1]
pred=(proba>=0.5).astype(int)

auc=roc_auc_score(yte,proba)
f1=f1_score(yte,pred)
print(f"AUC={auc:.3f}  F1={f1:.3f}")

# %% [markdown]
# ## 3. Выбор и обоснование метрик качества
#
# **Цель:** определить, какие метрики наиболее точно отражают качество модели для задачи бинарной классификации
# «выиграет ли игрок при данном действии».
#
# ---
#
# ### 3.1 Почему именно AUC и F1
#
# В нашей задаче важно не просто угадать, выиграет ли игрок, а **научиться различать выигрышные и проигрышные ситуации**.  
# При этом небольшие ошибки (ложные срабатывания) допустимы, но систематические смещения модели нежелательны.
# Для таких задач оптимально сочетание двух метрик:
#
# **1. AUC (Area Under the ROC Curve)**  
# - Показывает, насколько хорошо модель различает два класса — победу (`win=1`) и поражение (`win=0`).  
# - Измеряется как площадь под кривой «истинные положительные» против «ложных положительных».  
# - Интерпретация проста:  
#   AUC = 0.5 означает случайное угадывание (как подбрасывание монетки),  
#   AUC = 1.0 — идеальное разделение классов.  
# - В контексте покера AUC показывает, **насколько уверенно модель отличает удачные стратегии от проигрышных**, независимо от конкретного порога вероятности.
#
# **2. F1-score (гармоническое среднее между precision и recall)**  
# - Используется, когда классы сбалансированы, но важно не только предсказывать победы, а **не ошибаться с проигрышами**.  
# - Precision отвечает за то, насколько “чисты” предсказанные победы (мало ложных тревог),  
#   Recall — за то, насколько много реальных побед модель находит.  
# - F1 объединяет оба показателя и показывает общий баланс качества.  
# - Для игроков это аналог метрики «насколько часто я прав, когда считаю, что стратегия выиграет».
#
# ---
#
# ### 3.2 Почему не другие метрики
#
# - **Accuracy** (доля правильных ответов) не отражает уверенность модели и может вводить в заблуждение при несбалансированных данных.  
# - **Log-loss** или **MAE** сложнее интерпретировать без контекста вероятностей, что делает их менее наглядными для игрового анализа.  
# - В нашем случае важна именно способность **различать** исходы и **сохранять баланс между precision и recall**, поэтому выбор AUC + F1 обоснован.
#
# ---
#
# ### 3.3 Интерпретация результатов
#
# После обучения базовой модели логистической регрессии получены:  
# **AUC ≈ 0.60**, **F1 ≈ 0.65**.  
#
# Это означает:
# - модель действительно различает выигрышные и проигрышные действия лучше случайного угадывания;
# - F1 показывает умеренно сбалансированное качество: модель улавливает реальные победы, не создавая переизбытка ложных;
# - при дальнейшем развитии проекта можно оптимизировать гиперпараметры или фичи для роста AUC до 0.7–0.8.
#
# ---
#
# **Итог:**  
# Для данной задачи выбраны **AUC** (чувствительность модели к различию классов)  
# и **F1-score** (сбалансированная оценка точности и полноты).  
# Такое сочетание позволяет оценить не только правильность предсказаний, но и стратегическую точность модели —  
# насколько она уверенно отличает выигрышные действия от проигрышных.